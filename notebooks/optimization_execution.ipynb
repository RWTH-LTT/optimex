{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s  - %(levelname)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 21:42:07  - INFO - Creating sets\n",
      "2025-01-25 21:42:07  - INFO - Creating parameters\n",
      "2025-01-25 21:42:07  - INFO - Creating variables\n",
      "2025-01-25 21:42:07  - INFO - Creating expressions\n",
      "2025-01-25 21:47:05  - INFO - Creating constraints\n",
      "2025-01-25 21:47:05  - INFO - Creating objective function\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2026-01-20\n",
      "Read LP format model from file C:\\Users\\LAYTON~1\\AppData\\Local\\Temp\\tmpjb795t1y.pyomo.lp\n",
      "Reading time = 0.02 seconds\n",
      "x1: 1569 rows, 651 columns, 14108 nonzeros\n",
      "Set parameter MIPGap to value 0.01\n",
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (win64)\n",
      "Thread count: 6 physical cores, 6 logical processors, using up to 6 threads\n",
      "Optimize a model with 1569 rows, 651 columns and 14108 nonzeros\n",
      "Model fingerprint: 0xd331e91e\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-02, 1e+01]\n",
      "  Objective range  [3e-06, 7e-01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [6e+07, 7e+09]\n",
      "Warning: Model contains large rhs\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Presolve removed 1515 rows and 447 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 54 rows, 204 columns, 3720 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   2.112885e+10   0.000000e+00      0s\n",
      "      34    1.7049554e+08   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 34 iterations and 0.00 seconds (0.00 work units)\n",
      "Optimal objective  1.704955381e+08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 21:48:13  - INFO - Creating sets\n",
      "2025-01-25 21:48:13  - INFO - Creating parameters\n",
      "2025-01-25 21:48:13  - INFO - Creating variables\n",
      "2025-01-25 21:48:13  - INFO - Creating expressions\n",
      "2025-01-25 22:23:15  - INFO - Creating constraints\n",
      "2025-01-25 22:23:16  - INFO - Creating objective function\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2026-01-20\n",
      "Read LP format model from file C:\\Users\\LAYTON~1\\AppData\\Local\\Temp\\tmpqo5rns49.pyomo.lp\n",
      "Reading time = 0.07 seconds\n",
      "x1: 4049 rows, 1691 columns, 47696 nonzeros\n",
      "Set parameter MIPGap to value 0.01\n",
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (win64)\n",
      "Thread count: 6 physical cores, 6 logical processors, using up to 6 threads\n",
      "Optimize a model with 4049 rows, 1691 columns and 47696 nonzeros\n",
      "Model fingerprint: 0xc8883633\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-02, 1e+01]\n",
      "  Objective range  [9e-07, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [6e+07, 7e+09]\n",
      "Warning: Model contains large rhs\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "\n",
      "Concurrent LP optimizer: primal simplex, dual simplex, and barrier\n",
      "Showing barrier log only...\n",
      "\n",
      "Presolve removed 3995 rows and 1487 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 54 rows, 204 columns, 3720 nonzeros\n",
      "\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier performed 0 iterations in 0.01 seconds (0.01 work units)\n",
      "Barrier solve interrupted - model solved by another algorithm\n",
      "\n",
      "\n",
      "Solved with dual simplex\n",
      "Solved in 40 iterations and 0.01 seconds (0.01 work units)\n",
      "Optimal objective  1.529252293e+08\n"
     ]
    }
   ],
   "source": [
    "from optimex.converter import Converter\n",
    "from optimex import optimizer\n",
    "from optimex import postprocessing \n",
    "import pandas as pd\n",
    "\n",
    "con_vs = \"v8\"\n",
    "fixed = None\n",
    "for optimex_type in [\"dynamic_t50\", \"time_explicit_t130\"]:\n",
    "# for optimex_type in [\"time_explicit_t50\"]:\n",
    "\n",
    "    converter = Converter(None)\n",
    "    converter.unpickle_model_inputs(f\"data_ma/{optimex_type}_opt_inputs.pkl\")\n",
    "\n",
    "    converter.model_inputs.process_limits_max_default = 0.5e9\n",
    "    if converter.model_inputs.process_limits_max is None:\n",
    "        converter.model_inputs.process_limits_max = {}\n",
    "    for year in range(2020, 2051):\n",
    "        converter.model_inputs.process_limits_max.update({\n",
    "            (\"heat_prod_bio_gas_cogen\", year): 0.5*3.6e9,\n",
    "            (\"heat_prod_wood_chips_cogen\", year): 0.5*3.6e9,\n",
    "            (\"heat_prod_natural_gas_boiler\", year): 0.5*3.6e9,\n",
    "            (\"heat_prod_fuel_cell_cogen\", year): 0.5*3.6e9,\n",
    "        })\n",
    "    for year in range(2020, 2041):\n",
    "        converter.model_inputs.process_limits_max.update({\n",
    "            (\"heat_prod_fuel_cell_cogen\", year): 0.0,\n",
    "        }) \n",
    "    if converter.model_inputs.cumulative_process_limits_max is None:\n",
    "        converter.model_inputs.cumulative_process_limits_max = {}\n",
    "    converter.model_inputs.cumulative_process_limits_max.update({\n",
    "        \"heat_prod_natural_gas_boiler\": 2*3.6e9,\n",
    "        \"heat_prod_wood_chips_cogen\": 2*3.6e9,\n",
    "        \"elec_prod_hydro_run_of_river\": 0,\n",
    "        \"elec_prod_wind_offshore\": 0,\n",
    "        \"elec_prod_hydro_reservoir\": 1e9,\n",
    "        \"elec_prod_wind_onshore\": 1e9,    \n",
    "    })\n",
    "\n",
    "    converter.pickle_model_inputs(f\"data_ma/{optimex_type}_opt_with_{con_vs}_con_inputs.pkl\")\n",
    "\n",
    "    if fixed is not None:\n",
    "        fixed_scaling = pd.read_csv(f\"results/{fixed}_{con_vs}_opt_scaling.csv\", index_col=0)\n",
    "        model = optimizer.create_model(converter.model_inputs, name = f\"optimex_fixed_{optimex_type}\")\n",
    "        for time, row in fixed_scaling.iterrows():\n",
    "            for process in model.PROCESS:\n",
    "                if process in row:  # Ensure the process exists in the DataFrame columns\n",
    "                    value = row[process]\n",
    "                    if time in model.SYSTEM_TIME and process in model.PROCESS:\n",
    "                        model.scaling[process, time].fix(value)\n",
    "    else:\n",
    "        model = optimizer.create_model(converter.model_inputs, name = f\"optimex_{optimex_type}\")\n",
    "    model, results = optimizer.solve_model(model, compute_iis=True)\n",
    "    if fixed is not None:\n",
    "        results.write(filename=f\"results/{optimex_type}_{con_vs}_fixed_scaling_{fixed}_results.csv\")\n",
    "    else:\n",
    "        results.write(filename=f\"results/{optimex_type}_{con_vs}_opt_static_results.csv\")\n",
    "    pp = postprocessing.PostProcessor(model)\n",
    "    df_scaling = pp.get_scaling()\n",
    "    df_scaling.to_csv(f\"results/{optimex_type}_{con_vs}_opt_scaling.csv\")\n",
    "    dfs_production = pp.get_production()\n",
    "    for key, df in dfs_production.items():\n",
    "        df.to_csv(f\"results/{optimex_type}_{con_vs}_opt_{key}.csv\")\n",
    "    df_demand = pp.get_demand()\n",
    "    df_demand.to_csv(f\"results/{optimex_type}_{con_vs}_opt_demand.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['elec_prod_fuel_cell_cogen',\n",
       " 'heat_prod_bio_gas_cogen',\n",
       " 'heat_prod_natural_gas_boiler',\n",
       " 'elec_prod_bio_gas_cogen',\n",
       " 'heat_prod_fuel_cell_cogen',\n",
       " 'elec_prod_lignite',\n",
       " 'elec_prod_wood_chips_cogen',\n",
       " 'elec_prod_wind_offshore',\n",
       " 'elec_prod_wind_onshore',\n",
       " 'elec_prod_hydro_run_of_river',\n",
       " 'heat_prod_wood_chips_cogen',\n",
       " 'elec_prod_photovoltaic',\n",
       " 'elec_prod_hydro_reservoir']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter.model_inputs.PROCESS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
